We have implemented stacked denoising autoencoders and shown that it achieves accuracy comparable to state of the art classifiers like a SVM with RBF kernel. We also have shown that our autoencoder layers are learning good representations and are capable of denoising and reconstructing the input with little error. These learned representations improve the ability of other classification algorithms to correctly classify the data. We find that SGD scales well with increasing number of hidden units and with increasing number of threads. Lastly, we discovered that HGA, a genetic algorithm that makes use of gradient information, is competitive with SGD, and scales just as well if not better with the size of the autoencoder and number of threads. 
