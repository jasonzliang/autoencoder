As mentioned above, genetic algorithms are sensitive to their parameters. Consequently, much time and effort may be required in order to determine the optimal parameters and achieve good convergence performance. Without the correct parameters, the genetic algorithm may not converge to a solution at all or may converge very slowly. A technique known as metaoptimization could be used to automatically determine the correct parameters for performing the optimization. Grefenstette discusses this metaoptimization over six possible parameters for the genetic algorithm \cite{metaoptimization}. Finding the best possible parameters may result in better convergence for our genetic algorithms in both rate of error decrease and minimum error achieved.

Another direction to consider is adaptively selecting the probability of crossover or mutation during the training of the autoencoder. This so-called adaptive genetic algorithm reaches the global optimum for a cost function much more quickly than a standard genetic algorithm \cite{srinivas94adaptive}. This adaptive method could be applied to either CGA or to HGA and further improve it's performance.

Our experiments and results are based on shared memory, single machine parallelism. An interesting future topic to explore is expanding the methods we considered to more cores and more machines. Expanding to more cores is a trivial extension requiring just the appropriate multicore hardware with more than 16 processor cores on a node. Expanding what we have done to a distributed setting would require more work, and rewriting much of the code. Stochastic gradient descent has been shown to be a scalable method for a distributed setting (see, for example \cite{zinkevich2010psgd}) so it seems reasonable that it should scale in the application as well. Genetic algorithms have also been shown to demonstrate good scaling properties for distributed computations \cite{Belding95thedistributed}.
